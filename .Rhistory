data<-Titanic
str(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.7*nrow(data))
data_train<-data[indexes,]
data<-factor(data)
set.seed(42)
indexes=sample(1:nrow(data),0.7*nrow(data))
data<-Titanic
str(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.7*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
indexes=sample(1:nrow(data),0.75*nrow(data))
data_train<-data[indexes,]
target<-Survived ~ Class+Sex+Age
tree<-rpart(target,data=data_train,method="class")
data<-Titanic
str(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.75*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
target<-Survived ~ Class+Sex+Age
tree<-rpart(target,data=data_train,method="class")
rpart.plot(tree)
predictions<-predict(tree,data_test,type="class")
# decision tree on titanic dataset
library(ggplot2)
data<-as.data.frame(Titanic)
str(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.75*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
target<-Survived ~ Class+Sex+Age
tree<-rpart(target,data=data_train,method="class")
rpart.plot(tree)
predictions<-predict(tree,data_test,type="class")
confusion_Matrix<-table(data_test$Survived,predictions)
confusion_Matrix
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
accuracy
# decision tree on titanic dataset
library(rpart)
library(rpart.plot)
data<-as.data.frame(Titanic)
str(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.75*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
target<-Survived ~ Class+Sex+Age
tree<-rpart(target,data=data_train,method="class")
rpart.plot(tree)
predictions<-predict(tree,data_test,type="class")
confusion_Matrix<-table(data_test$Survived,predictions)
confusion_Matrix
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
accuracy
table(data_train$Survived)
table(data_train$Survived)
table(data_test$Survived)
# decision tree on titanic dataset
library(rpart)
library(rpart.plot)
data<-as.data.frame(Titanic)
str(data)
View(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.75*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
target<-Survived ~ Class+Sex+Age
tree<-rpart(target,data=data_train,method="class")
rpart.plot(tree)
predictions<-predict(tree,data_test,type="class")
table(data_train$Survived)
table(data_test$Survived)
confusion_Matrix<-table(data_test$Survived,predictions,dnn = c("predicted","actual"))
confusion_Matrix
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
accuracy
# decision tree on titanic dataset
library(rpart)
library(rpart.plot)
data<-as.data.frame(Titanic)
str(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.7*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
target<-Survived ~ Class+Sex+Age
tree<-rpart(target,data=data_train,method="class")
rpart.plot(tree)
predictions<-predict(tree,data_test,type="class")
table(data_train$Survived)
table(data_test$Survived)
confusion_Matrix<-table(data_test$Survived,predictions,dnn = c("predicted","actual"))
confusion_Matrix
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
accuracy
# ann on prostate cancer
data<-read.csv("C://lpu//5th sem//INT234//CA//CA2//Prostate_cancer.csv",stringsAsFactors = FALSE)
str(data)
summary(data)
nrow(data)
hist(data$fractal_dimension)
normalize<-function(x){
return ((x-min(x))/(max(x)-min(x)))
}
data<-data[,sapply(data,is.numeric)]
data_norm<-as.data.frame(lapply(data,normalize))
data_train<-data_norm[1:70,]
data_test<-data_norm[71:100,]
library(neuralnet)
colnames(data)
prostate_model<-neuralnet(fractal_dimension ~ radius+texture+perimeter+area+smoothness+compactness+symmetry
,data=data_train)
plot(prostate_model)
prostate_model_results<-compute(prostate_model,data_test[3:9])
predicted_dimension<-prostate_model_results$net.result
cor(predicted_dimension,data_test$fractal_dimension)
print(paste("Accuracy": prostate_model$r_squared))
print(paste("Accuracy":, prostate_model$r_squared))
print(paste("Accuracy":+ prostate_model$r_squared))
print(paste("Accuracy:"+prostate_model$r_squared))
print(paste("Accuracy:"+prostate_model$r_squared))
# ann on prostate cancer
data<-read.csv("C://lpu//5th sem//INT234//CA//CA2//Prostate_cancer.csv",stringsAsFactors = FALSE)
str(data)
summary(data)
nrow(data)
hist(data$fractal_dimension)
normalize<-function(x){
return ((x-min(x))/(max(x)-min(x)))
}
data<-data[,sapply(data,is.numeric)]
data_norm<-as.data.frame(lapply(data,normalize))
data_train<-data_norm[1:70,]
data_test<-data_norm[71:100,]
library(neuralnet)
colnames(data)
prostate_model<-neuralnet(fractal_dimension ~ radius+texture+perimeter+area+smoothness+compactness+symmetry
,data=data_train)
plot(prostate_model)
prostate_model_results<-compute(prostate_model,data_test[3:9])
predicted_dimension<-prostate_model_results$net.result
cor(predicted_dimension,data_test$fractal_dimension)
print(paste("Accuracy:"+prostate_model$r_squared))
confusion_Matrix<-table(data_test$fractal_dimension,predicted_dimension,dnn = c("predicted","actual"))
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
print(paste("Accuracy: ",accuracy))
accuracy <- mean(abs(predicted_dimension - data_test$fractal_dimension))
print(paste("Accuracy:", ))
print(paste("Accuracy:", accuracy))
print(paste("Accuracy: ",accuracy*1))
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
print(paste("Accuracy: ",accuracy*1))
print(paste("Accuracy: ",accuracy*10))
print(paste("Accuracy: ",accuracy*100))
print(paste("Accuracy: ",accuracy*100,"%"))
# decision tree on titanic dataset
library(rpart)
library(rpart.plot)
data<-as.data.frame(Titanic)
str(data)
View(data)
nrow(data)
set.seed(42)
indexes=sample(1:nrow(data),0.7*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
target<-Survived ~ Class+Sex+Age
tree<-rpart(target,data=data_train,method="class")
rpart.plot(tree)
predictions<-predict(tree,data_test,type="class")
table(data_train$Survived)
table(data_test$Survived)
confusion_Matrix<-table(data_test$Survived,predictions,dnn = c("predicted","actual"))
confusion_Matrix
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
print(paste("Accuracy: ",accuracy*100,"%"))
# ann on prostate cancer
data<-read.csv("C://lpu//5th sem//INT234//CA//CA2//Prostate_cancer.csv",stringsAsFactors = FALSE)
str(data)
summary(data)
nrow(data)
hist(data$fractal_dimension)
normalize<-function(x){
return ((x-min(x))/(max(x)-min(x)))
}
data<-data[,sapply(data,is.numeric)]
data_norm<-as.data.frame(lapply(data,normalize))
data_train<-data_norm[1:70,]
data_test<-data_norm[71:100,]
library(neuralnet)
colnames(data)
prostate_model<-neuralnet(fractal_dimension ~ radius+texture+perimeter+area+smoothness+compactness+symmetry
,data=data_train)
plot(prostate_model)
prostate_model_results<-compute(prostate_model,data_test[3:9])
predicted_dimension<-prostate_model_results$net.result
cor(predicted_dimension,data_test$fractal_dimension)
confusion_Matrix<-table(data_test$fractal_dimension,predicted_dimension,dnn = c("predicted","actual"))
accuracy=sum(diag(confusion_Matrix))/sum(confusion_Matrix)
print(paste("Accuracy: ",accuracy*100,"%"))
load("C:/lpu/5th sem/INT234/Code/.RData")
library("arules")
data("Groceries")   # this dataset is the part of the library arules
View(Groceries)
summary(Groceries)
str(Groceries)
# Look for first five items
inspect(Groceries[1:5])
#examine the frequency of items
itemFrequency(Groceries[,1:3])
# plot the frequency of items
itemFrequencyPlot(Groceries)
itemFrequencyPlot(Groceries, support=0.1)
itemFrequencyPlot(Groceries, topN=20)
# a visualization of the sparse matrix for the first five transactions
image(Groceries[1:5])
# visualization of a random sample of 100 transactions
image(sample(Groceries,100))
library("arules")
data("Groceries")   # this dataset is the part of the library arules
summary(Groceries)
str(Groceries)
# Look for first five items
inspect(Groceries[1:5])
#examine the frequency of items
itemFrequency(Groceries[,1:3])
# plot the frequency of items
itemFrequencyPlot(Groceries)
itemFrequencyPlot(Groceries, support=0.1)
itemFrequencyPlot(Groceries, topN=20)
# a visualization of the sparse matrix for the first five transactions
image(Groceries[1:5])
# visualization of a random sample of 100 transactions
image(sample(Groceries,100))
# training the model on data
# set better support and confidence levels to learn more rules
groceryrules<-apriori(Groceries,
parameter = list(support=0.006, confidence=0.25,minlen=2))
?apriori
groceryrules
# evaluating the model performance ------- summary of grocery association rules
summary(groceryrules)
# look at the first three rules
inspect(groceryrules[1:3])
# improving the model performance
inspect(groceryrules[1:10],lift=0.5)
# sorting grocery rules by lift
inspect(sort(groceryrules,by="lift")[1:5])
# finding the subsets of rules containing any berry items
berryrules<-subset(groceryrules,items%in%"berries")
inspect(berryrules)
# finding the subsets of rules that precede soda purchases
sodarules<-subset(groceryrules,rhs %in% "soda")
inspect(sodarules)
top.soda.rules<-head(sort(sodarules, by="lift"),5)
inspect(top.soda.rules)
# writing the rules into a csv file
write(groceryrules, file = "C:/lpu/5th sem/INT234/Code/groceryrules.csv", sep=",",
quote=TRUE, row.names=FALSE)
getwd()
# converting the rule set into a dataframe
groceryrules_df<-as(groceryrules,"data.frame")
str(groceryrules_df)
Groceries
?apriori
gc()
gc()
install.packages("randomForest")
# loading the necessary packages
library(randomForest)
rfNews()
install.packages(c("glue", "parallelly", "Rcpp", "tm"))
install.packages(c("glue", "parallelly", "Rcpp", "tm"))
# load the dataset
data("iris")
set.seed(42)
sample_index<-sample(1:nrow(iris),0.7*nrow(iris))
train_data<-iris[sample_index,]
test_data<-iris[-sample_index,]
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=100)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix))
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# loading the necessary packages
library(randomForest)
# load the dataset
data("iris")
set.seed(42)
sample_index<-sample(1:nrow(iris),0.7*nrow(iris))
train_data<-iris[sample_index,]
test_data<-iris[-sample_index,]
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=50)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=50, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# loading the necessary packages
library(randomForest)
# load the dataset
data("iris")
set.seed(42)
sample_index<-sample(1:nrow(iris),0.7*nrow(iris))
train_data<-iris[sample_index,]
test_data<-iris[-sample_index,]
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=50, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=150, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=10, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=0, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=1, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=10, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=65, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=10, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=10, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# loading the necessary packages
library(randomForest)
# load the dataset
data("iris")
set.seed(42)
sample_index<-sample(1:nrow(iris),0.7*nrow(iris))
train_data<-iris[sample_index,]
test_data<-iris[-sample_index,]
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=10, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
# loading the necessary packages
library(randomForest)
# load the dataset
data("iris")
set.seed(42)
sample_index<-sample(1:nrow(iris),0.7*nrow(iris))
train_data<-iris[sample_index,]
test_data<-iris[-sample_index,]
# train the model
rf_model<-randomForest(Species ~ ., data = train_data, ntree=10, mtry=2)
# model summary
rf_model
# predict the test set
predictions<-predict(rf_model,test_data)
# confusion matrix to evaluate the model
confusion_matrix<-table(predictions, test_data$Species)
confusion_matrix
print(sum(diag(confusion_matrix))/sum(confusion_matrix)*100)
data<-read.csv("C://lpu//5th sem//INT234//Datasets//students.csv")
library(arules)
library(cluster)
head(data)
set.seed(42)
kmeans.re<-kmeans(data,centers = 3,nstart = 2)
str(data)
data<-data[-1,]
head(data)
str(data)
set.seed(42)
kmeans.re<-kmeans(data,centers = 3,nstart = 2)
data<-read.csv("C://lpu//5th sem//INT234//Datasets//students.csv")
data<-data[,-1]
head(data)
str(data)
set.seed(42)
kmeans.re<-kmeans(data,centers = 3,nstart = 2)
kmeans.re
kmeans.re$cluster
kmeans.re$centers
cm<-table(data$marks,kmeans.re)
cm<-table(data$marks,kmeans.re$cluster)
cm
print(paste("Accuracy: ",sum(diag(cm))/sum(cm)*100),"%")
print(paste("Accuracy: ",sum(diag(cm))/sum(cm)*100,"%"))
plot(data[c("roll_no","marks")])
plot(data[c("roll_no","marks")])
plot(data[c("roll_no","marks")],col=kmeans.re$cluster, main="K-means clustering with 2 clusters")
kmeans.re$centers[,c("roll_no","marks")]
points(kmeans.re$centers[,c("roll_no","marks")],col=1:3,pch=8,cex=3)
y_kmeans<-kmeans.re$cluster
clusplot(data,[,c("roll_no","marks")],y_kmeans,lines=0,shade=TRUE,color=TRUE,labels=2,plotchar=FALSE,span=TRUE,main=paste("Cluster of students"),xlab='Roll No',ylab='Marks')
clusplot(data[,c("roll_no","marks")],y_kmeans,lines=0,shade=TRUE,color=TRUE,labels=2,plotchar=FALSE,span=TRUE,main=paste("Cluster of students"),xlab='Roll No',ylab='Marks')
library(arules)
library(cluster)
data<-read.csv("C://lpu//5th sem//INT234//Datasets//students.csv")
data<-data[,-1]
head(data)
str(data)
set.seed(42)
kmeans.re<-kmeans(data,centers = 3,nstart = 2)
kmeans.re
kmeans.re$cluster
kmeans.re$centers
cm<-table(data$marks,kmeans.re$cluster)
cm
print(paste("Accuracy: ",sum(diag(cm))/sum(cm)*100,"%"))
plot(data[c("roll_no","marks")],col=kmeans.re$cluster, main="K-means clustering with 2 clusters")
kmeans.re$centers[,c("roll_no","marks")]
points(kmeans.re$centers[,c("roll_no","marks")],col=1:3,pch=8,cex=3)
y_kmeans<-kmeans.re$cluster
clusplot(data[,c("roll_no","marks")],y_kmeans,lines=0,shade=TRUE,color=TRUE,labels=2,plotchar=FALSE,span=TRUE,main=paste("Cluster of students"),xlab='Roll No',ylab='Marks')
