data<-read.csv(file.choose())
data
str(data)
# got to know that class can be a factor
data$class<-factor(data$class)
nrow(data)
ncol(data)
data_train<-data[1:16544,]
data_test<-data[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(e1071)
data_classifier<-naiveBayes(data_train,data_train_labels)
data_pred<-predict(data_classifier,data_test)
a=table(data_pred,data_test_labels)
a
library(gmodels)
CrossTable(data_pred,data_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))
library(caret)
confusionMatrix(a)
# knn on intrusion dataset
data<-read.csv(file.choose())
data
normalise<-function(x){
return(x-min(x)/max(x)-min(x))
}
data
nrow(data)
ncol(data)
normalise<-function(x){
return(x-min(x)/max(x)-min(x))
}
data_n<-as.data.frame(lapply(data,normalise))
data_n<-as.data.frame(lapply(data[1:42],normalise))
data
data$class<-factor(data$class)
nrow(data)
ncol(data)
round(prop.table(table(data$class))*100,digits = 1)
normalise<-function(x){
return(x-min(x)/max(x)-min(x))
}
data_n<-as.data.frame(lapply(data[1:42],normalise))
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[1:42],normalise))
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data[1:16544,]
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
# knn on intrusion dataset
data<-read.csv(file.choose())
data
data$class<-factor(data$class)
nrow(data)
ncol(data)
round(prop.table(table(data$class))*100,digits = 1)
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(class)
wbcd_test_prepd<-knn(train = data_train, test = data_test,cl=data_train_labels,k=21)
library(gmodels)
CrossTable(x=data_test_labels,y=data_test_prepd,prop.chisq=FALSE)  # this gives the details about the number of values matched and not matched while testing
data_test_prepd<-knn(train = data_train, test = data_test,cl=data_train_labels,k=21)
library(gmodels)
CrossTable(x=data_test_labels,y=data_test_prepd,prop.chisq=FALSE)  # this gives the details about the number of values matched and not matched while testing
aa<-table(data_test_labels,data_test_prepd)
library(caret)
confusionMatrix(aa)  #this tells about the accuracy of the model
# knn on intrusion dataset
data<-read.csv(file.choose())
data
data$class<-factor(data$class)
nrow(data)
ncol(data)
round(prop.table(table(data$class))*100,digits = 1)
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(class)
data_test_prepd<-knn(data_train, data_test,data_train_labels,k=21)
library(gmodels)
CrossTable(x=data_test_labels,y=data_test_prepd,prop.chisq=FALSE)  # this gives the details about the number of values matched and not matched while testing
aa<-table(data_test_labels,data_test_prepd)
library(caret)
confusionMatrix(aa)  #this tells about the accuracy of the model
table(data$class)
# knn on intrusion dataset
data<-read.csv(file.choose())
data
data$class<-factor(data$class)
nrow(data)
ncol(data)
table(data$class)
round(prop.table(table(data$class))*100,digits = 1)
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(class)
data_test_prepd<-knn(data_train, data_test,data_train_labels,k=21)
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(class)
data_test_prepd<-knn(data_train, data_test,data_train_labels,k=21)
library(gmodels)
CrossTable(x=data_test_labels,y=data_test_prepd,prop.chisq=FALSE)  # this gives the details about the number of values matched and not matched while testing
aa<-table(data_test_labels,data_test_prepd)
library(caret)
confusionMatrix(aa)  #this tells about the accuracy of the model
# knn on diamond dataset
library(dplyr)
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
View(data)
colnames(data)
ncol(data)
nrow(data)
str(data)
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
View(data)
colnames(data)
str(data)
# by analyzing dataset, we can make cut as a factor and it is a factor
ncol(data)
nrow(data)
table(data$cut)
library(class)
round(prop.table(table(data$cut))*100,digits=1)
summary(data[c("depth","table","price","x","y","z")])
normalize<-function(x){
return((x-min(x)/(max(x)-min(x))))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
gc()
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
colnames(data)
str(data)
# by analyzing dataset, we can make cut as a factor and it is a factor
ncol(data)
nrow(data)
table(data$cut)
round(prop.table(table(data$cut))*100,digits=1)
summary(data[c("depth","table","price","x","y","z")])
normalize<-function(x){
return((x-min(x)/(max(x)-min(x))))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
View(daat_n)
View(data_n)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:53940,]
data_train_labels<-data[1:45000,2]
data_test_labels<-data[45001:53940,2]
data_test_prepd<-knn(data_train,data_test,data_train_labels,k=30)
data_test_prepd<-knn(data_train,data_test,data_train_labels,k=25)
gc()
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
View(data)
colnames(data)
str(data)
# by analyzing dataset, we can make cut as a factor and it is a factor
ncol(data)
nrow(data)
table(data$cut)
round(prop.table(table(data$cut))*100,digits=1)
summary(data[c("depth","table","price","x","y","z")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:53940,]
data_train_labels<-data[1:45000,2]
data_test_labels<-data[45001:53940,2]
data_test_prepd<-knn(data_train,data_test,data_train_labels,k=25)
# naive bayes algorithm on diamonds dataset
data<-diamonds
# naive bayes algorithm on diamonds dataset
data<-diamonds
nrow(data)
ncol(data)
# naive bayes algorithm on diamonds dataset
data<-diamonds
nrow(data)
ncol(data)
data_train<-data[1:45000,]
data_test<-data[45001:53940,]
data_train_labels<-data[1:45000,]$cut
data_test_labels<-data[45001:53940,]$cut
library(e1071)
data_classifier<-naiveBayes(data_train,data_train_labels)
data_pred<-predict(data_test,data_classifier)
data_pred<-predict(data_classifier,data_test)
a=table(data_pred,data_test_labels)
CrossTable(data_pred,data_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))
confusionMatrix(a)
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
View(data)
colnames(data)
str(data)
# by analyzing dataset, we can make cut as a factor and it is a factor
ncol(data)
nrow(data)
table(data$cut)
round(prop.table(table(data$cut))*100,digits=1)
summary(data[c("depth","table","price","x","y","z")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:nrow(data),]
data_train_labels<-data[1:45000,'cut']
data_test_labels<-data[45001:nrow(data),'cut']
data_test_prepd<-knn(data_train,data_test,data_train_labels,k=25)
data_test_prepd<-knn(train=data_train,test=data_test,class=data_train_labels,k=25)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=25)
length(data_train)
length(data_train_labels)
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
colnames(data)
str(data)
# by analyzing dataset, we can make cut as a factor and it is a factor
data$cut<-as.factor(data$cut)
ncol(data)
nrow(data)
table(data$cut)
round(prop.table(table(data$cut))*100,digits=1)
summary(data[c("depth","table","price","x","y","z")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:nrow(data),]
data_train_labels<-data[1:45000,'cut']
data_test_labels<-data[45001:nrow(data),'cut']
length(data_train)
length(data_train_labels)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=25)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:nrow(data),]
# Reset row names to ensure proper indexing
rownames(data_train) <- NULL
rownames(data_test) <- NULL
data_train_labels<-data[1:45000,'cut']
data_test_labels<-data[45001:nrow(data),'cut']
length(data_train)
length(data_train_labels)
length(wbcd_train)
wbcd<-read.csv("wisc_bc_data.csv",stringsAsFactors = FALSE)
str(wbcd) #tells the structure of the data
View(wbcd)
wbcd<-wbcd[-1] #removing the first column from the data since the ID is not useful for the anlaysis
table(wbcd$diagnosis)  #gives the count of unique strings
wbcd$diagnosis<-factor(wbcd$diagnosis,levels=c("B","M"),labels=c("Benign","Malignant"))
round(prop.table(table(wbcd$diagnosis))*100,digits = 1)  # prop means proportion. this actually tells the proportion of the values present in the field
summary(wbcd[c("radius_mean","area_mean","smoothness_mean")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
wbcd_n<-as.data.frame(lapply(wbcd[2:31],normalize))
summary(wbcd_n$area_mean)
wbcd_train<-wbcd_n[1:469,]  #using 470 samples to train
wbcd_test<-wbcd_n[470:569,]  #using 100 samples to test
wbcd_train_labels<-wbcd[1:469,1]
wbcd_test_labels<-wbcd[470:569,1]
length(wbcd_train)
length(wbcd_train_labels)
library(class)
wbcd_test_prepd<-knn(train = wbcd_train, test = wbcd_test,cl=wbcd_train_labels,k=21)
library(gmodels)
CrossTable(x=wbcd_test_labels,y=wbcd_test_prepd,prop.chisq=FALSE)  # this gives the details about the number of values matched and not matched while testing
aa<-table(wbcd_test_labels,wbcd_test_prepd)
library(caret)
confusionMatrix(aa)  #this tells about the accuracy of the model
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
colnames(data)
str(data)
# by analyzing dataset, we can make cut as a factor and it is a factor
data$cut<-as.factor(data$cut)
ncol(data)
nrow(data)
table(data$cut)
round(prop.table(table(data$cut))*100,digits=1)
summary(data[c("depth","table","price","x","y","z")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:nrow(data_n),]
data_train_labels<-data[1:45000,'cut']
data_test_labels<-data[45001:nrow(data),'cut']
length(data_train)
length(data_train_labels)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=25)
CrossTable(x=data_train_labels,y=data_test_prepd,prop.chisq = FALSE)
View(data)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=5)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=255)
# knn on intrusion dataset
data<-read.csv(file.choose())
data
data$class<-factor(data$class)
nrow(data)
ncol(data)
table(data$class)
round(prop.table(table(data$class))*100,digits = 1)
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(class)
data_test_prepd<-knn(data_train, data_test,data_train_labels,k=21)
library(gmodels)
gc()
gc()
# knn on diamond dataset
library(class)
library(caret)
library(gmodels)
data<-diamonds
colnames(data)
str(data)
# by analyzing dataset, we can make cut as a factor and it is a factor
data$cut<-as.factor(data$cut)
ncol(data)
nrow(data)
table(data$cut)
round(prop.table(table(data$cut))*100,digits=1)
summary(data[c("depth","table","price","x","y","z")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:10],normalize))
summary(data_n)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:nrow(data_n),]
data_train_labels<-data[1:45000,'cut']
data_test_labels<-data[45001:nrow(data),'cut']
length(data_train)
length(data_train_labels)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=25)
data_train<-data_n[1:45000,]
data_test<-data_n[45001:nrow(data_n),]
data_train_labels<-data[1:45000,]$cut
data_test_labels<-data[45001:nrow(data),]$cut
length(data_train)
length(data_train_labels)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=25)
CrossTable(x=data_train_labels,y=data_test_prepd,prop.chisq = FALSE)
CrossTable(x = data_test_labels, y = data_test_prepd, prop.chisq = FALSE)
a<-table(data_test_labels,data_test_prepd)
confusionMatrix(a)
data_test_prepd<-knn(train=data_train,test=data_test,cl=data_train_labels,k=50)
CrossTable(x = data_test_labels, y = data_test_prepd, prop.chisq = FALSE)
a<-table(data_test_labels,data_test_prepd)
confusionMatrix(a)
# knn on intrusion dataset
data<-read.csv(file.choose())
data
data$class<-factor(data$class)
nrow(data)
ncol(data)
table(data$class)
round(prop.table(table(data$class))*100,digits = 1)
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(class)
data_test_prepd<-knn(data_train, data_test,data_train_labels,k=21)
library(gmodels)
CrossTable(x=data_test_labels,y=data_test_prepd,prop.chisq=FALSE)  # this gives the details about the number of values matched and not matched while testing
aa<-table(data_test_labels,data_test_prepd)
library(caret)
confusionMatrix(aa)  #this tells about the accuracy of the model
library(rpart)
library(rpart.plot)
data<-read.csv("C://lpu//5th sem//INT234//Datasets//intrusion_detection_data.csv")
str(data)
nrow(data)
ncol(data)
set.seed(1234)
indexes<-sample(1:nrow(data),0.70*nrow(data))
data_train<-data[indexes,]
data_test<-data[-indexes,]
target<- class ~ src_bytes +	dst_bytes +	land +	wrong_fragment +	urgent +	hot +	num_failed_logins +	logged_in +	num_compromised +	root_shell +	su_attempted +	num_root +	num_file_creations +	num_shells +	num_access_files +	num_outbound_cmds +	is_host_login +	is_guest_login +	count +	srv_count +	serror_rate +	srv_serror_rate +	rerror_rate +	srv_rerror_rate +	same_srv_rate +	diff_srv_rate +	srv_diff_host_rate +	dst_host_count +	dst_host_srv_count +	dst_host_same_srv_rate +	dst_host_diff_srv_rate +	dst_host_same_src_port_rate +	dst_host_srv_diff_host_rate +	dst_host_serror_rate +	dst_host_srv_serror_rate +	dst_host_rerror_rate +	dst_host_srv_rerror_rate
tree<-rpart(target, data=data_train, method = "class")
rpart.plot(tree)
predictions<-predict(tree,data_test,type="class")
confusion_matrix<-table(data_test$class,predictions)
print(confusion_matrix)
accuracy<-sum(diag(confusion_matrix))/sum(confusion_matrix)
print(paste("Accuracy: ",round(accuracy*100,4)))
# naive bayes on intrusion detection
data<-read.csv(file.choose())
data
View(data)
str(data)
# got to know that class can be a factor
data$class<-factor(data$class)
nrow(data)
ncol(data)
data_train<-data[1:16544,]
data_test<-data[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(e1071)
data_classifier<-naiveBayes(data_train,data_train_labels)
data_pred<-predict(data_classifier,data_test)
a=table(data_pred,data_test_labels)
a
library(gmodels)
CrossTable(data_pred,data_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))
library(caret)
confusionMatrix(a)
# knn on intrusion dataset
data<-read.csv(file.choose())
data
data$class<-factor(data$class)
nrow(data)
ncol(data)
table(data$class)
round(prop.table(table(data$class))*100,digits = 1)
normalise<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_n<-as.data.frame(lapply(data[5:41],normalise))
data_train<-data_n[1:16544,]
data_test<-data_n[16545:25192,]
data_train_labels<-data[1:16544,]$class
data_test_labels<-data[16545:25192,]$class
library(class)
data_test_prepd<-knn(data_train, data_test,data_train_labels,k=21)
library(gmodels)
CrossTable(x=data_test_labels,y=data_test_prepd,prop.chisq=FALSE)  # this gives the details about the number of values matched and not matched while testing
aa<-table(data_test_labels,data_test_prepd)
library(caret)
confusionMatrix(aa)  #this tells about the accuracy of the model
