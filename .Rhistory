l2[[2]][1]<-NULL  #only possible if it is a element in a list inside a list. if a element in a vector inside a list, it won't work and throw an error. but we can make an entire vector as NULL which is present in a list
l2[3][1]<-NULL  #only possible if it is a element in a list inside a list. if a element in a vector inside a list, it won't work and throw an error. but we can make an entire vector as NULL which is present in a list
]
l2[[3]][1]<-NULL  #only possible if it is a element in a list inside a list. if a element in a vector inside a list, it won't work and throw an error. but we can make an entire vector as NULL which is present in a list
l2
# operators
# assignment operator
a<-1
a=1
a<<-1
b<<-1
a+b
#logical operators
a<-c(1:10)
b<-c(21:30)
mat1<-matrix(a,nrow=2,ncol = 6,byrow=TRUE)
mat1<-matrix(a,nrow=2,ncol = 6,byrow=TRUE)
mat2<-matrix(b,nrow=2,ncol=6,byrow=TRUE)
mat1
mat1
mat2
mat1%*%t(mat2)  # since the multiplication will be done only if ncol=nrow
# factors
# create a factor for blood samples
lev<-c('A+','A-','B+','B-','O-','O+')
# knn algorithm considering Breast Cancer data
getwd()
wbcd<-read.csv("wisc_bc_data.csv",stringsAsFactors = FALSE)
str(wbcd) #tells the structure of the data
wbcd<-wbcd[-1] #removing the first column from the data since the ID is not useful for the anlaysis
table(wbcd$diagnosis)  #gives the count of unique strings
wbcd$diagnosis<-factor(wbcd$diagnosis,levels=c("B","M"),labels=c("Benign","Malignant"))
View(wbcd)
round(prop.table(table(wbcd$diagnosis))*100,digits = 1)  # prop means proportion. this actually tells the proportion of the values present in the field
# knn algorithm considering Breast Cancer data
getwd()
wbcd<-read.csv("wisc_bc_data.csv",stringsAsFactors = FALSE)
str(wbcd) #tells the structure of the data
View(wbcd)
wbcd<-wbcd[-1] #removing the first column from the data since the ID is not useful for the anlaysis
table(wbcd$diagnosis)  #gives the count of unique strings
wbcd$diagnosis<-factor(wbcd$diagnosis,levels=c("B","M"),labels=c("Benign","Malignant"))
View(wbcd)
round(prop.table(table(wbcd$diagnosis))*100,digits = 1)  # prop means proportion. this actually tells the proportion of the values present in the field
round(prop.table(table(wbcd$diagnosis))*100,digits = 1)  # prop means proportion. this actually tells the proportion of the values present in the field
summary(wbcd[c("radius_mean","area_mean","smoothness_mean")])
irisd<-as.data.frame(iris)
str(irisd)
irisd
table(irisd$Species)
irisd$Species<-factor(irisd$Species,levels=c("setosa","versicolor","virginica"),labels = c("Setosa","Versicolor","Virginica"))
round(prop.table(table(irisd$Species))*100,digits = 1)
summary(irisd[c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
irisd_n<-as.data.frame(lapply(irisd[1:4],normalize))
summary(irisd_n)
str(irisd_n)
irisd_train<-irisd_n[1:100,]
irisd_test<-irisd_n[101:150,]
irisd_train_labels<-irisd[1:100,5]
irisd_test_labels<-irisd[101:150,5]
library(class)
irisd_test_prepd<-knn(train = irisd_train,test = irisd_test,class=irisd_train_labels,k=30)
library(gmodels)
CrossTable(x=irisd_test_labels,y=irisd_test_prepd,prop.chisq=FALSE)
irisd_test_prepd<-knn(train = irisd_train,test = irisd_test,cl=irisd_train_labels,k=30)
library(gmodels)
CrossTable(x=irisd_test_labels,y=irisd_test_prepd,prop.chisq=FALSE)
bb<-table(irisd_test_labels,irisd_test_prepd)
library(caret)
confusionMatrix(bb)
irisd<-as.data.frame(iris)
str(irisd)
irisd
table(irisd$Species)
irisd$Species<-factor(irisd$Species,levels=c("setosa","versicolor","virginica"),labels = c("Setosa","Versicolor","Virginica"))
round(prop.table(table(irisd$Species))*100,digits = 1)
summary(irisd[c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
irisd_n<-as.data.frame(lapply(irisd[1:4],normalize))
summary(irisd_n)
str(irisd_n)
irisd_train<-irisd_n[1:100,]
irisd_test<-irisd_n[101:150,]
irisd_train_labels<-irisd[1:100,5]
irisd_test_labels<-irisd[101:150,5]
library(class)
irisd_test_prepd<-knn(train = irisd_train,test = irisd_test,cl=irisd_train_labels,k=30)
library(gmodels)
CrossTable(x=irisd_test_labels,y=irisd_test_prepd,prop.chisq=FALSE)
irisd<-as.data.frame(iris)
str(irisd)
irisd
table(irisd$Species)
irisd$Species<-factor(irisd$Species,levels=c("setosa","versicolor","virginica"),labels = c("Setosa","Versicolor","Virginica"))
round(prop.table(table(irisd$Species))*100,digits = 1)
summary(irisd[c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
irisd_n<-as.data.frame(lapply(irisd[1:4],normalize))
summary(irisd_n)
str(irisd_n)
irisd_train<-irisd_n[1:100,]
irisd_test<-irisd_n[101:150,]
irisd_train_labels<-irisd[1:100,5]
irisd<-as.data.frame(iris)
str(irisd)
irisd
table(irisd$Species)
irisd$Species<-factor(irisd$Species,levels=c("setosa","versicolor","virginica"),labels = c("Setosa","Versicolor","Virginica"))
round(prop.table(table(irisd$Species))*100,digits = 1)
summary(irisd[c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
irisd_n<-as.data.frame(lapply(irisd[1:4],normalize))
summary(irisd_n)
str(irisd_n)
irisd_train<-irisd_n[1:100,]
irisd_test<-irisd_n[101:150,]
irisd_train_labels<-irisd[1:100,5]
irisd_test_labels<-irisd[101:150,5]
library(class)
irisd_test_prepd<-knn(train = irisd_train,test = irisd_test,cl=irisd_train_labels,k=10)
library(gmodels)
CrossTable(x=irisd_test_labels,y=irisd_test_prepd,prop.chisq=FALSE)
irisd<-as.data.frame(iris)
str(irisd)
irisd
table(irisd$Species)
irisd$Species<-factor(irisd$Species,levels=c("setosa","versicolor","virginica"),labels = c("Setosa","Versicolor","Virginica"))
round(prop.table(table(irisd$Species))*100,digits = 1)
summary(irisd[c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")])
normalize<-function(x){
return((x-min(x))/(max(x)-min(x)))
}
irisd_n<-as.data.frame(lapply(irisd[1:4],normalize))
summary(irisd_n)
str(irisd_n)
irisd_train<-irisd_n[1:100,]
irisd_test<-irisd_n[101:150,]
irisd_train_labels<-irisd[1:100,5]
irisd_test_labels<-irisd[101:150,5]
library(class)
irisd_test_prepd<-knn(train = irisd_train,test = irisd_test,cl=irisd_train_labels,k=10)
irisd_test_prepd <- factor(irisd_test_prepd, levels = levels(irisd_test_labels))
library(gmodels)
CrossTable(x=irisd_test_labels,y=irisd_test_prepd,prop.chisq=FALSE)
bb<-table(irisd_test_labels,irisd_test_prepd)
library(caret)
confusionMatrix(bb)
data<-read.csv("C://lpu//5th sem//INT234//Datasets//sms_spam.csv")
data
View(data)
gc()
data<-read.csv("C://lpu//5th sem//INT234//Datasets//sms_spam.csv")
View(data)
str(data)
#Naive Bayes Algorithm
# useful for prediction of new data from the previous learnings
sms_raw<-read.csv("C://lpu//5th sem//INT234//Datasets//sms_spam.csv")
View(sms_raw)
str(sms_raw)
#Naive Bayes Algorithm
# useful for prediction of new data from the previous learnings
sms_raw<-read.csv("C://lpu//5th sem//INT234//Datasets//sms_spam.csv",stringsAsFactors = FALSE)
View(sms_raw)
class(sms_raw)
str(sms_raw)
class(sms_raw$type)
class(sms_raw$text)
# can directly use str(sms_raw)
sms_raw$type<-factor(sms_raw$type)
class(sms_raw$type)
library(tm)
sms_corpus<-VCorpus(VectorSource(sms_raw$text))
View(sms_corpus)
# using VCorpus to change the text column into a document
sms_corpus<-VCorpus(VectorSource(sms_raw$text))
View(sms_corpus)
sms_corpus_clean<-tm_map(sms_corpus,content_transformer(tolower))
sms_corpus_clean<-tm_map(sms_corpus_clean,removeNumbers)
stopwords()
sms_corpus_clean<-tm_map(sms_corpus_clean,removeWords)
sms_corpus_clean<-tm_map(sms_corpus_clean,removeWords)
sms_corpus_clean<-tm_map(sms_corpus_clean,removeWords,stopwords())
sms_corpus_clean<-tm_map(sms_corpus_clean,removePunctuation)
wordstem(c(learn,learnt,learned))
# wordstem() is used to extract the rootwords
sms_corpus_clean<-tm_map(sms_corpus_clean,stemDocument)
sms_corpus_clean<-tm_map(sms_corpus_clean,stripWhitespace) # removing extra whitespaces present in the document
sms_dtm<-DocumentTermMatrix(sms_corpus_clean)
sms_dtm
#Training the model from the cleaned data
sms_dtm_train<-sms_dtm[1:4169,]  # for training the model from dataset
sms_dtm_test<-sms_dtm[4170:5559,]  # for testing the model after training
sms_train_labels<-sms_raw[1:4169,]$type  #labels for the training data
sms_test_labels<-sms_raw[4170:5559,]$type  #labels for the testing data
sms_freq_words<-findFreqTerms(sms_dtm_train,5)  # checking the frequency of the words which atleast got repeated 5 times to make it a spam message else not considered
sms_dtm_freq_train<-sms_dtm_train[,sms_freq_words]
sms_dtm_freq_test<-sms_dtm_test[,sms_freq_words]
convert_counts<-function(x){
x<-ifelse(x>0,"Yes","No")
}
sms_train<-apply(sms_dtm_freq_train,MARGIN = 2, convert_counts)
sms_test<-apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier<-naiveBayes(sms_train,sms_train_labels)
sms_test_pred<-predict(sms_classifier,sms_test)  #predicting the sms whether it is spam or ham using the test dataset from the trained data
a=table(sms_test_pred,sms_test_labels)
a
library(gmodels)
CrossTable(sms_test_pred,sms_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))
library(caret)
confusionMatrix(a)
sms_train
#Naive Bayes Algorithm
# useful for prediction of new data from the previous learnings
sms_raw<-read.csv("C://lpu//5th sem//INT234//Datasets//sms_spam.csv",stringsAsFactors = FALSE)
gc()
gc()
#Naive Bayes Algorithm
# useful for prediction of new data from the previous learnings
sms_raw<-read.csv("C://lpu//5th sem//INT234//Datasets//sms_spam.csv",stringsAsFactors = FALSE)
#checking the datatype of every column of the data
class(sms_raw$type)
class(sms_raw$text)
# can directly use str(sms_raw)
sms_raw$type<-factor(sms_raw$type)  #changing the data into factor from chr
class(sms_raw$type) #checking whether the type has been changed or not
library(tm)
# using VCorpus to change the text column into a corpus (collection of text documents) for text mining
sms_corpus<-VCorpus(VectorSource(sms_raw$text))
View(sms_corpus)
#Cleaning the data
sms_corpus_clean<-tm_map(sms_corpus,content_transformer(tolower))  # cleaning the data in text column but by lowcasing all characters in every row of the text column for better computation to the rcompiler as the ascii values of the lowercase letters will be less compared to uppercase
sms_corpus_clean<-tm_map(sms_corpus_clean,removeNumbers)  # removing the numbers present in every row of the text column
stopwords() #checking the stopwords in the r library
sms_corpus_clean<-tm_map(sms_corpus_clean,removeWords,stopwords())  # removing the stopwords if any are present in the rows of text column
sms_corpus_clean<-tm_map(sms_corpus_clean,removePunctuation)  # removing the punctuations in the sentences so that if any punctuation was present in the text won't be considered as spam
# wordstem() is used to extract the rootwords
sms_corpus_clean<-tm_map(sms_corpus_clean,stemDocument)  # extracting the rootwords present in the sentences using stemDocument
sms_corpus_clean<-tm_map(sms_corpus_clean,stripWhitespace) # removing extra whitespaces present in the document
sms_dtm<-DocumentTermMatrix(sms_corpus_clean)  # to check the presence of particular word in the particular document
# here rows represent documents (SMS messages) and columns represent terms (words)
sms_dtm
#Training the model from the cleaned data
sms_dtm_train<-sms_dtm[1:4169,]  # for training the model from dataset
sms_dtm_test<-sms_dtm[4170:5559,]  # for testing the model after training
sms_train_labels<-sms_raw[1:4169,]$type  #labels for the training data
sms_test_labels<-sms_raw[4170:5559,]$type  #labels for the testing data
sms_freq_words<-findFreqTerms(sms_dtm_train,5)  # checking the frequency of the words which atleast got repeated 5 times to make it a spam message else not considered
# Keep only the columns (terms) that meet the frequency threshold in both the training and test sets.
sms_dtm_freq_train<-sms_dtm_train[,sms_freq_words]
sms_dtm_freq_test<-sms_dtm_test[,sms_freq_words]
# function that checks the value  of x i.e. count of a word in a document is greater than 0 or not. If greater than zero, marks it as Yes else No
convert_counts<-function(x){
x<-ifelse(x>0,"Yes","No")
}
#applying the function on dtm matrix with train and test data
sms_train<-apply(sms_dtm_freq_train,MARGIN = 2, convert_counts)
sms_train
sms_test<-apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
library(e1071)
sms_classifier<-naiveBayes(sms_train,sms_train_labels)  # using naive bayes algorithm to train the model
sms_test_pred<-predict(sms_classifier,sms_test)  #predicting the sms whether it is spam or ham using the test dataset from the trained data
a=table(sms_test_pred,sms_test_labels)
a
library(gmodels)
CrossTable(sms_test_pred,sms_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
iris_raw<-read.csv(iris)
iris_raw<-iris
View(iris_raw)
str(iris_raw)
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:69,]
iris_test<-iris_raw[70:150,]
iris_train_labels<-iris_raw[1:69,]$Species
iris_test_labels<-iris_raw[70:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
iris_raw<-iris
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:99,]
iris_test<-iris_raw[100:150,]
iris_train_labels<-iris_raw[1:99,]$Species
iris_test_labels<-iris_raw[100:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:125,]
iris_test<-iris_raw[126:150,]
iris_train_labels<-iris_raw[1:125,]$Species
iris_test_labels<-iris_raw[126:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:125,]
iris_test<-iris_raw[126:150,]
iris_train_labels<-iris_raw[1:125,]$Species
iris_test_labels<-iris_raw[126:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:100,]
iris_test<-iris_raw[101:150,]
iris_train_labels<-iris_raw[1:100,]$Species
iris_test_labels<-iris_raw[101:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:99,]
iris_test<-iris_raw[100:150,]
iris_train_labels<-iris_raw[1:99,]$Species
iris_test_labels<-iris_raw[100:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:125,]
iris_test<-iris_raw[126:150,]
iris_train_labels<-iris_raw[1:125,]$Species
iris_test_labels<-iris_raw[126:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:150,]
iris_test<-iris_raw[1:150,]
iris_train_labels<-iris_raw[1:150,]$Species
iris_test_labels<-iris_raw[1:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:66,]
iris_test<-iris_raw[67:150,]
iris_train_labels<-iris_raw[1:66,]$Species
iris_test_labels<-iris_raw[67:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
iris_raw<-iris
str(iris_raw)
# no need of data mining and data cleaning
iris_train<-iris_raw[1:75,]
iris_test<-iris_raw[76:150,]
iris_train_labels<-iris_raw[1:75,]$Species
iris_test_labels<-iris_raw[76:150,]$Species
library(e1071)
iris_classifier<-naiveBayes(iris_train,iris_train_labels)
iris_test_pred<-predict(iris_classifier,iris_test)
a=table(iris_test_pred,iris_test_labels)
a
library(gmodels)
CrossTable(iris_test_pred,iris_test_labels,prop.chisq = FALSE,prop.t = FALSE,dnn = c('predicted','actual'))  # making a table which tells about how many values have been predicted correctly classified by predicted and actual
library(caret)
confusionMatrix(a)
# Load the dataset
iris_raw <- iris
# Check structure of dataset (optional)
str(iris_raw)
# Ensure species column is a factor (it already is in the iris dataset)
# Just to be sure:
iris_raw$Species <- as.factor(iris_raw$Species)
# Randomly shuffle the dataset to avoid biased partitioning
set.seed(123)  # For reproducibility
random_indices <- sample(1:nrow(iris_raw))
# Shuffle the dataset
iris_raw <- iris_raw[random_indices, ]
# Split into training (70%) and testing (30%) datasets
train_size <- floor(0.7 * nrow(iris_raw))  # 70% of the data
iris_train <- iris_raw[1:train_size, ]
iris_test <- iris_raw[(train_size + 1):nrow(iris_raw), ]
# Extract labels
iris_train_labels <- iris_train$Species
iris_test_labels <- iris_test$Species
# Remove the label column from training and test sets to use only features for the model
iris_train <- iris_train[, -5]  # Remove 'Species' column
iris_test <- iris_test[, -5]    # Remove 'Species' column
# Load the Naive Bayes package
library(e1071)
# Train the model
iris_classifier <- naiveBayes(iris_train, iris_train_labels)
# Make predictions on the test data
iris_test_pred <- predict(iris_classifier, iris_test)
# Create a confusion matrix
a <- table(iris_test_pred, iris_test_labels)
print(a)
# Create a cross table to compare actual vs predicted values
library(gmodels)
CrossTable(iris_test_pred, iris_test_labels, prop.chisq = FALSE, prop.t = FALSE, dnn = c('predicted', 'actual'))
# Generate detailed performance metrics using caret's confusionMatrix function
library(caret)
confusionMatrix(a)
# Load the dataset
iris_raw <- iris
# Check structure of dataset (optional)
str(iris_raw)
# Ensure species column is a factor (it already is in the iris dataset)
# Just to be sure:
iris_raw$Species <- as.factor(iris_raw$Species)
# Randomly shuffle the dataset to avoid biased partitioning
set.seed(123)  # For reproducibility
random_indices <- sample(1:nrow(iris_raw))
# Shuffle the dataset
iris_raw <- iris_raw[random_indices, ]
# Split into training (70%) and testing (30%) datasets
train_size <- floor(0.7 * nrow(iris_raw))  # 70% of the data
iris_train <- iris_raw[1:train_size, ]
iris_test <- iris_raw[(train_size + 1):nrow(iris_raw), ]
# Extract labels
iris_train_labels <- iris_train$Species
iris_test_labels <- iris_test$Species
# Remove the label column from training and test sets to use only features for the model
iris_train <- iris_train[, -5]  # Remove 'Species' column
iris_test <- iris_test[, -5]    # Remove 'Species' column
# Load the Naive Bayes package
library(e1071)
# Train the model
iris_classifier <- naiveBayes(iris_train, iris_train_labels)
# Make predictions on the test data
iris_test_pred <- predict(iris_classifier, iris_test)
# Create a confusion matrix
a <- table(iris_test_pred, iris_test_labels)
print(a)
# Create a cross table to compare actual vs predicted values
library(gmodels)
CrossTable(iris_test_pred, iris_test_labels, prop.chisq = FALSE, prop.t = FALSE, dnn = c('predicted', 'actual'))
# Generate detailed performance metrics using caret's confusionMatrix function
library(caret)
confusionMatrix(a)
iris_raw
